# Нагрузочное тестирование — Bybit Algo-Grid / стратегия AVI-5

Документ описывает подход к нагрузочному тестированию системы
**Bybit Algo-Grid System / стратегия AVI-5**:

- какие сценарии нагрузки моделируются;
- какие метрики снимаются;
- какие пороговые значения считаются приемочными для релиза;
- как нагрузочные тесты связаны с мониторингом и алертингом.

Документ дополняет `docs/test_plan.md` и ориентирован на разработчиков, QA и SRE.

---

## 1. Цели и ограничения

### 1.1. Цели

- Подтвердить, что система выдерживает ожидаемую и пиковую нагрузку по:
  - входящим WebSocket-данным (рыночные данные, сигналы);
  - исходящим запросам к Bybit (REST, при необходимости WS);
  - внутренним операциям с Redis и PostgreSQL.
- Проверить, что под нагрузкой:
  - сохраняется корректность обработки сигналов и позиций;
  - `/health` и `/metrics` отражают состояние системы;
  - kill-switch и алерты срабатывают предсказуемо.
- Задать **конкретные численные пороги**, при выходе за которые релиз не допускается в прод.

### 1.2. Не цели

- Документ не фиксирует конкретный инструмент нагрузочного тестирования (k6/JMeter и т.п.) и не описывает синтаксис скриптов — это реализуется отдельно.
- Документ не заменяет `docs/test_plan.md`, а лишь детализирует его раздел про нагрузочные тесты.

---

## 2. Общие принципы нагрузочного тестирования

1. **Нагрузка — ближе к реальной**  
   - Моделируем паттерны, похожие на реальный рынок: bursts, flat-периоды, резкие шипы.
   - Комбинируем фоновой поток данных и пики.

2. **Тестируем на отдельном контуре**  
   - Нагрузочные тесты запускаются на **staging**-окружении,
     сконфигурированном максимально близко к прод (см. `docs/deployment.md`).
   - Для запросов к Bybit используется testnet или изолированный mock-сервер.

3. **“Нагрузка + поведение”**  
   - Важно не только «выдержал/не выдержал», но и то, **как именно** система деградирует:
     - меняется ли код ответа `/health`;
     - растёт ли latency;
     - появляются ли ошибки в логах и алертах.

4. **Репитабельность**  
   - Сценарии и значения нагрузки должны быть воспроизводимыми, чтобы можно было сравнивать релизы.

---

## 3. Сценарии нагрузочного тестирования

### 3.1. Сценарий LT-WS-01 — Высокий поток WebSocket-данных

**Цель:** проверить устойчивость обработки входящих WS-стримов (рыночные данные, сигналы) и доставки их в:

- внутренние очереди и обработчики;
- SSE-стрим `/stream` для клиентов;
- хранилище (PostgreSQL/Redis) — если применимо.

**Описание сценария:**

1. Эмулятор WS-данных генерирует сообщения с частотой:
   - **целевой уровень** — X1 сообщений/сек (ожидаемая рабочая нагрузка);
   - **стресс-уровень** — X2 = 2×X1 сообщений/сек.
2. Сообщения содержат:
   - обновления цен/клинов для whitelisted-символов;
   - события, эквивалентные сигналам стратегии (при необходимости).
3. Одновременно:
   - поднимается N клиентов SSE `/stream`, которые подписаны на события `signal` и `position`;
   - фиксируется latency между генерацией события и доставкой до клиента.

**Метрики:**

- `ws_messages_per_second` — входящий поток на стороне приложения.
- `stream_delivery_latency_p95/p99` — задержка доставки SSE-событий.
- `event_loop_lag` (если есть соответствующая метрика).
- `backend_cpu_usage` / `backend_mem_usage`.
- Количество ошибок обработки WS (exceptions, reconnects и т.п.).

**Пороговые значения (стэйдж):**

- При нагрузке на уровне X1:
  - `stream_delivery_latency_p95` ≤ 150 мс;
  - отсутствуют `5xx` по API;
  - `event_loop_lag_p95` ≤ 50 мс;
  - нет потерь сообщений (кол-во доставленных ≈ кол-ву сгенерированных).
- При нагрузке на уровне X2 (стресс, 15 минут):
  - `stream_delivery_latency_p95` ≤ 500 мс;
  - допустим единичный рост ошибок, но не более 0.1% от общего числа сообщений;
  - `/health` не переходит в `degraded`/`down` из-за перегрева CPU/памяти.

---

### 3.2. Сценарий LT-REST-01 — Шипы latency Bybit API

**Цель:** проверить устойчивость outbound-интеграций при:

- увеличении времени ответа Bybit;
- частичных сбоях (5xx, rate limiting).

**Описание сценария:**

1. На уровне тестового стенда Bybit или mock-сервера:
   - внедряются случайные задержки ответа: **от 100 мс до 1500 мс**;
   - симулируются ошибки:
     - 1–2% ответов `5xx`;
     - 1–2% ответов с ошибками rate limiting.
2. На стороне AVI-5 запускаются:
   - обычный поток торговых событий (создание/закрытие позиций);
   - периодические запросы к REST эндпоинтам Bybit (балансы, позиции).

**Метрики:**

- `bybit_http_latency_p95/p99` — latency запросов к Bybit.
- `bybit_http_error_rate` — доля неуспешных запросов.
- Время внутренних операций (создание/закрытие позиции).
- Состояние retry/бэкофф механизма (кол-во повторных попыток на единицу времени).
- Состояние kill-switch и алертов по Bybit (см. `monitoring/alerts.yml`).

**Пороговые значения:**

- `bybit_http_error_rate` ≤ 5% на интервал теста (включая симулируемые ошибки).
- Ретраи не приводят к «шторму» запросов (бурстов на порядок выше baseline).
- Внутренние операции по созданию/закрытию позиции:
  - `p95` ≤ 2 c;
  - при систематическом превышении → релиз отклоняется.
- `/health` должен переключиться в состояние `degraded` при длительной недоступности Bybit,
  но не в `down`, если БД/Redis и сам backend живы.

---

### 3.3. Сценарий LT-DB-01 — Деградация PostgreSQL/Redis

**Цель:** оценить поведение системы при проблемах с БД/Redis:

- снижении производительности (IO/CPU);
- кратковременной недоступности;
- росте времени ответа.

**Описание сценария:**

1. В тестовом окружении искусственно ограничить ресурсы:
   - уменьшить IOPS/черезput для тома БД;
   - задать ограничение CPU/памяти для контейнера Postgres/Redis.
2. Запустить типичную нагрузку:
   - поток сигналов и создание позиций;
   - чтение и обновление конфигурации;
   - операции логина/аутентификации.

**Метрики:**

- Latency SQL-запросов (`db_query_latency_p95/p99`), количество timeout’ов.
- Latency операций Redis (`redis_latency_p95/p99`).
- Количество ошибок обращения к БД/Redis.
- Состояние `/health` (компоненты `db` и `redis`).
- Уровень degradata: наличие алертов `db_slow_queries`, `redis_slow_ops` (см. `monitoring/alerts.yml`).

**Пороговые значения:**

- При умеренной деградации ресурсов:
  - `/health` может перейти в `degraded`, но не в `down`;
  - error rate API (5xx) ≤ 1% на интервал теста.
- При кратковременной недоступности (до 30 сек):
  - количество 5xx ограничено; приложение не падает, а корректно восстанавливает коннекты;
  - после восстановления БД нет потери консистентности позиций/сигналов.

---

### 3.4. Сценарий LT-SOAK-01 — Длительная нагрузка (soak test)

**Цель:** проверить поведение системы при длительной (8–12 часов) работе под среднестатистической нагрузкой.

**Описание сценария:**

- Запуск фоновой нагрузки, соответствующей:
  - среднему потоку WebSocket-сообщений;
  - умеренному количеству REST-запросов к Bybit;
  - нормальному количеству пользовательских операций (логин, просмотр сигналов, чтение позиций).
- В ходе теста:
  - отслеживаются утечки памяти;
  - проверяется стабильность latency и error rate;
  - проверяется отсутствие роста очередей и лагов event loop.

**Пороговые значения:**

- Отсутствие систематического роста потребления памяти (линейный тренд вверх → повод для расследования).
- Стабильные показатели latency (без дрейфа p95/p99).
- Отсутствие рестартов контейнеров по OOM/CrashLoopBackOff.

---

## 4. Метрики и пороговые значения (сводная таблица)

| Метрика                          | Описание                                     | Порог (стэйдж)                   |
|----------------------------------|----------------------------------------------|----------------------------------|
| `stream_delivery_latency_p95`    | latency доставки SSE-событий                 | ≤ 150 мс (рабочая нагрузка)      |
| `stream_delivery_latency_p95`    | то же, стресс-нагрузка X2                    | ≤ 500 мс                         |
| `event_loop_lag_p95`            | лаг event loop                               | ≤ 50 мс на рабочей нагрузке     |
| `api_error_rate`                | доля 5xx по публичным эндпоинтам             | ≤ 1%                             |
| `bybit_http_error_rate`         | доля ошибок запросов к Bybit                 | ≤ 5% (включая симулируемые)     |
| `db_query_latency_p95`          | latency SQL-запросов                         | ≤ 200 мс                         |
| `redis_latency_p95`             | latency операций Redis                       | ≤ 50 мс                          |
| `backend_cpu_usage`             | средняя загрузка CPU                         | ≤ 70% при рабочей нагрузке      |
| `backend_mem_usage`             | использование памяти                         | без устойчивого роста/утечек    |
| `ws_messages_loss_rate`         | доля потерянных WS-сообщений                 | ≈ 0%                             |

> Конкретные имена метрик должны совпадать с теми, что экспортируются в `/metrics`
> и используются в `monitoring/alerts.yml`. При изменении имён/структуры метрик
> данный документ необходимо обновить.

---

## 5. Процесс запуска нагрузочных тестов

### 5.1. Когда запускаются нагрузочные тесты

- Перед **крупными релизами** (изменения торговой логики, интеграции с Bybit, работы с БД).
- После существенных изменений в подсистемах:
  - обработка WS/stream;
  - архитектура хранения данных;
  - механизм retry/бэкофф.
- Периодически по расписанию (например, раз в неделю) — короткие прогонные тесты LT-WS-01, LT-REST-01.

### 5.2. Кто отвечает

- За планирование и запуск нагрузочных тестов отвечает технический владелец сервиса и/или SRE.
- Результаты тестов фиксируются:
  - в системе CI (если тесты интегрированы);
  - в виде отчёта (краткое описание сценариев, использованные параметры, метрики, выводы).

### 5.3. Критерии прохождения/провала релиза

Релиз **НЕ допускается** в прод, если:

- нарушены пороговые значения из раздела 4;
- наблюдаются:
  - падения приложения (crash loop);
  - невозможность восстановления после кратковременных инцидентов БД/Redis/Bybit;
  - существенные проблемы с консистентностью данных (позиции/сигналы).

Переход в прод возможен только после:

- анализа причин нарушений;
- фиксации и исправления проблем;
- успешного повторного прогона сценариев нагрузочного тестирования.

---

## 6. Связанные документы

- `docs/test_plan.md` — общий план тестирования, в котором нагрузочные тесты упомянуты как один из типов.
- `docs/deployment.md` — описание стэйдж/прод окружений и требований к ресурсам.
- `docs/disaster_recovery.md` — сценарии аварийного восстановления; нагрузочные тесты не должны противоречить целевым RTO/RPO.
- `docs/backup_strategy.md` — стратегия backup’ов, которая определяет ограничение по дополнительной нагрузке на БД.
- `monitoring/alerts.yml` — набор алертов по latency/error rate/kill-switch и др., с которыми должны коррелировать результаты нагрузочных тестов.

