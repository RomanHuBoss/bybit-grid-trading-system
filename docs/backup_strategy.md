# Стратегия резервного копирования — Bybit Algo-Grid / AVI-5

Настоящий документ описывает стратегию резервного копирования базы данных
системы **Bybit Algo-Grid / стратегия AVI-5** и требования к восстановлению данных.

Основные цели:

- обеспечение **RPO (Recovery Point Objective)** на уровне **5 минут**;
- возможность восстановления БД в заданную точку времени (PITR);
- защита от потери данных при сбоях оборудования, человеческих ошибках и инцидентах в ЦОД.

Значения RPO согласованы с DR-планом (`docs/disaster_recovery.md`) и общими
требованиями к доступности системы.

---

## 1. Типы бэкапов и расписание

### 1.1. Полный бэкап БД

- Тип: физический или логический backup всей БД (через `pg_dump` / `pg_basebackup`).
- Частота: **1 раз в сутки**.
- Время запуска: **ежедневно в 03:00 UTC**.
- Инструмент:
  - скрипт `scripts/backup.py`, выполняющий:
    - запуск `pg_dump` (или эквивалентного механизма полного backup’а);
    - упаковку результата в архив (`.tar` / аналогичный формат);
    - загрузку архива в S3-совместимое хранилище.

Рекомендуется запускать полный backup в период минимальной торговой активности,
чтобы снизить нагрузку на БД.

### 1.2. Инкрементальный бэкап через WAL-архивирование

Для достижения RPO = 5 минут используются журналируемые изменения (WAL):

- включено **continuous WAL archiving**:
  - каждый завершённый WAL-сегмент автоматически отправляется в S3/MinIO;
- частота фактического появления архивов зависит от нагрузки на БД;
- при необходимости используются механизмы `archive_command` / `restore_command`
  и/или сторонние инструменты, поддерживающие WAL-архивирование.

Таким образом, между полными backup’ами есть непрерывная цепочка WAL,
позволяющая выполнить восстановление в произвольную точку времени
(см. раздел 4).

---

## 2. Политика хранения бэкапов

### 2.1. Локальное хранение

- Локально (на хосте БД или отдельном backup-хосте) хранятся:
  - полные backup’ы и необходимые WAL-архивы **за последние 7 дней**.
- Цель:
  - быстрое восстановление при локальных сбоях и кратковременных инцидентах;
  - минимизация времени на скачивание больших объёмов данных из S3.

Очистка локального хранилища может выполняться либо средствами ОС (cron + `find`),
либо через вспомогательные скрипты, но не должна приводить к нарушению цепочки
WAL, необходимой для восстановления в пределах заявленного RPO.

### 2.2. Хранение в S3/MinIO

Основное долговременное хранилище — S3-совместимый объектный storage:

- в S3/MinIO размещаются:
  - ежедневные полные backup’ы;
  - все WAL-архивы, обеспечивающие непрерывность восстановления.
- Срок хранения:
  - **90 дней** с момента создания backup’а.
- Политика жизненного цикла:
  - в течение первых **30 дней** объекты хранятся в основном (горячем) классе;
  - после **30 дней** объекты автоматически переводятся в слой **Glacier / cold storage**
    (или эквивалентный класс, в зависимости от провайдера).

Очистка старых бэкапов осуществляется:

- с помощью `cleanup_old_backups` из `scripts/backup.py` (удаление старых объектов);
- и/или через S3 Lifecycle Policy (для перевода в Glacier и удаления после 90 дней).

Важно: даже при использовании автоматической lifecycle-политики в S3, логика
скрипта не должна нарушать непрерывность WAL в пределах RPO/RTO.

---

## 3. Целевой RPO и его обеспечение

### 3.1. RPO = 5 минут

- Допустимая потеря данных по времени — **не более 5 минут**.
- RPO достигается за счёт:
  - ежедневных полных backup’ов (точки опоры);
  - непрерывного WAL-архивирования (continuous archiving).

На практике это означает, что при корректной работе backup-процесса мы можем:

1. Восстановить БД на момент последнего полного backup.
2. Применить WAL-сегменты вплоть до момента инцидента (или нужной точки времени),
   с точностью до нескольких минут.

### 3.2. Практические требования

Для выполнения RPO необходимо:

- следить за наличием и непрерывностью WAL-цепочки в S3;
- контролировать успеваемость выгрузки WAL (чтобы не задерживалась из-за сети или ограничений S3);
- следить за тем, чтобы локальные очистки (rotate) не удаляли WAL раньше, чем они гарантированно
  попали в S3 и там зафиксированы.

---

## 4. Процедура восстановления

Высокоуровневая процедура восстановления БД из backup’ов следующая:

1. Определить **целевую точку восстановления** — `backup_timestamp`:
   - обычно это момент времени за ≤ 5 минут до начала инцидента;
   - фиксируется в UTC.
2. Вызвать скрипт восстановления с указанием целевого времени.

### 4.1. Скрипт `scripts/restore_db.sh`

Для упрощения операций используется обёртка:

```bash
scripts/restore_db.sh <backup_timestamp>
````

где `<backup_timestamp>` — строка времени/идентификатор, используемый
для выбора нужного полного backup’а и цепочки WAL (формат и правила указаны
в описании скрипта).

Задачи `restore_db.sh` (на уровне идеи):

* выбрать подходящий полный backup (<= целевая точка);
* скачать нужный backup из S3 (при необходимости — через `scripts/restore.py`);
* восстановить БД через `pg_restore` или аналогичный механизм;
* применить WAL до выбранной точки (PITR);
* запустить/перезапустить PostgreSQL с обновлёнными данными.

### 4.2. Скрипты `scripts/backup.py` и `scripts/restore.py`

Технические детали:

* `scripts/backup.py`:

  * выполняет `pg_dump` в файл;
  * архивирует результат;
  * загружает в S3;
  * очищает старые backup’ы (локально и/или в S3) согласно политике хранения.
* `scripts/restore.py`:

  * скачивает указанный backup-файл из S3;
  * выполняет `pg_restore` (или аналогичную процедуру) в целевую БД.

Сценарий вызова этих скриптов может быть скрыт внутри `restore_db.sh` и cron-задач;
главное — не нарушать заявленную стратегию RPO/RTO.

---

## 5. Проверка целостности и тестовые восстановления

### 5.1. Автоматическая проверка целостности

Необходимо регулярно проверять, что backup’ы **пригодны к восстановлению**:

* **Автоматическое тестовое восстановление — не реже 1 раза в неделю**:

  1. Разворачивается отдельный тестовый стенд БД (отдельный инстанс PostgreSQL).
  2. Выполняется восстановление по процедуре раздела 4
     на момент недавнего backup’а (например, «-24 часа от текущего времени»).
  3. Запускаются минимальные smoke-тесты:

     * наличие ключевых таблиц;
     * базовое количество записей;
     * корректность схем (согласно миграциям).

Результаты тестового восстановления фиксируются (логируются) и при необходимости
разбираются с командой разработки/ops.

### 5.2. DR-учения

В дополнение к еженедельной проверке целостности backup’ов:

* не реже одного раза в квартал проводится **полноценное DR-учение** (см. `docs/disaster_recovery.md`),
  которое включает:

  * имитацию аварии;
  * восстановление БД из backup’ов;
  * замер фактических RTO/RPO;
  * анализ и документирование результатов.

---

## 6. Организация каталогов и соглашения об именах

### 6.1. Локальные каталоги

Рекомендуемые каталоги:

* `/var/backups/avi5/full/` — полные backup’ы за последние 7 дней;
* `/var/backups/avi5/wal/` — локальная копия WAL (при необходимости).

Пример имени файла полного backup’а:

```text
avi5_full_2025-01-10T03-00-00Z.tar
```

Где:

* `2025-01-10T03-00-00Z` — время начала backup’а в UTC.

### 6.2. S3-структура

Рекомендуемая структура ключей в S3:

* `s3://<bucket>/avi5/full/YYYY/MM/DD/avi5_full_<timestamp>.tar`
* `s3://<bucket>/avi5/wal/YYYY/MM/DD/<wal_segment>.tar` (или без `.tar`, по договорённости).

Такая структура позволяет:

* легко удалять backup’ы старше нужного возраста (по префиксам и дате);
* настраивать lifecycle-политику S3 по префиксам и времени.

---

## 7. Мониторинг и алертинг backup-процесса

Для backup- и restore-процессов должны собираться базовые метрики и логи:

* успешность/ошибки выполнения `scripts/backup.py` и `scripts/restore_db.sh`;
* длительность выполнения backup’ов;
* время с момента последнего успешного backup’а;
* статус WAL-архивирования.

Рекомендуется:

* интегрировать эти метрики в существующую систему мониторинга (Prometheus + Grafana);
* добавить алерты:

  * «нет успешного полного backup’а более N часов»;
  * «ошибка backup’а/restore’а»;
  * «отсутствуют новые WAL-архивы более M минут».

Конкретная реализация алертов может быть описана в `monitoring/alerts.yml`
и/или дополнительной документации по мониторингу.

---

## 8. Ответственность и актуализация

* За настройку и поддержку backup-процессов отвечает выделенная ops/SRE-команда
  (или иное ответственное лицо, указанное в договоре).
* Настоящий документ должен пересматриваться:

  * при изменении версии PostgreSQL;
  * при изменении схемы хранения (переезд на другой S3/облако);
  * по итогам DR-учений и инцидентов, связанных с потерей/повреждением данных.
* Любые изменения в стратегии резервного копирования должны согласовываться с
  владельцем системы и быть синхронизированы с `docs/disaster_recovery.md`.
